{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T08:05:37.593522Z",
     "start_time": "2025-06-23T08:05:37.580558Z"
    }
   },
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "\n",
    "def read_time_machine():\n",
    "    with open('local_poem.txt', 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n",
    "\n",
    "\n",
    "lines = read_time_machine()\n",
    "print(f'text lines: {len(lines)}')\n",
    "print(lines[0])\n",
    "print(lines[10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text lines: 75\n",
      "in a quiet corner of the world there lay an ancient forest its edges blurred by mist and time few dared to enter for tales spoke of strange lights haunting sounds and paths that twisted back on themselves but for leo a curious fifteen year old with a heart full of wonder it was an irresistible mystery\n",
      "as he watched the images shifted now he saw a young girl her eyes as bright as the stars running through the very same forest she seemed to be searching for something her expression filled with determination leo felt a strange connection to her as if their fates were intertwined\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T08:05:43.762391Z",
     "start_time": "2025-06-23T08:05:43.748428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize(lines, token='word'):\n",
    "    \"\"\"将文本行拆分为单词或字符标记\"\"\"\n",
    "    if token == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    elif token == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    else:\n",
    "        print('错误：未知令牌类型：' + token)\n",
    "        return None\n",
    "\n",
    "\n",
    "tokens = tokenize(lines)\n",
    "for i in range(11):\n",
    "    print(tokens[i])"
   ],
   "id": "1b2359099b66279c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'a', 'quiet', 'corner', 'of', 'the', 'world', 'there', 'lay', 'an', 'ancient', 'forest', 'its', 'edges', 'blurred', 'by', 'mist', 'and', 'time', 'few', 'dared', 'to', 'enter', 'for', 'tales', 'spoke', 'of', 'strange', 'lights', 'haunting', 'sounds', 'and', 'paths', 'that', 'twisted', 'back', 'on', 'themselves', 'but', 'for', 'leo', 'a', 'curious', 'fifteen', 'year', 'old', 'with', 'a', 'heart', 'full', 'of', 'wonder', 'it', 'was', 'an', 'irresistible', 'mystery']\n",
      "[]\n",
      "['one', 'crisp', 'morning', 'with', 'the', 'sun', 'just', 'peeking', 'over', 'the', 'horizon', 'leo', 'slipped', 'out', 'of', 'his', 'small', 'village', 'the', 'grass', 'under', 'his', 'feet', 'was', 'damp', 'and', 'the', 'air', 'carried', 'the', 'sweet', 'scent', 'of', 'wildflowers', 'as', 'he', 'approached', 'the', 'forest', 'the', 'mist', 'seemed', 'to', 'part', 'as', 'if', 'inviting', 'him', 'in']\n",
      "[]\n",
      "['the', 'first', 'step', 'inside', 'was', 'like', 'crossing', 'a', 'threshold', 'into', 'another', 'world', 'the', 'trees', 'were', 'towering', 'giants', 'their', 'trunks', 'gnarled', 'and', 'covered', 'in', 'moss', 'sunlight', 'filtered', 'through', 'the', 'leaves', 'in', 'thin', 'golden', 'streams', 'creating', 'a', 'patchwork', 'of', 'light', 'and', 'shadow', 'on', 'the', 'forest', 'floor', 'strange', 'birds', 'chirped', 'from', 'hidden', 'branches', 'their', 'calls', 'unlike', 'any', 'leo', 'had', 'ever', 'heard']\n",
      "[]\n",
      "['he', 'walked', 'along', 'a', 'narrow', 'path', 'his', 'boots', 'crunching', 'on', 'fallen', 'twigs', 'every', 'now', 'and', 'then', 'he', 'paused', 'to', 'listen', 'to', 'the', 'whispers', 'of', 'the', 'wind', 'in', 'the', 'leaves', 'as', 'if', 'they', 'were', 'sharing', 'secrets', 'only', 'he', 'could', 'hear', 'as', 'he', 'went', 'deeper', 'the', 'path', 'began', 'to', 'climb', 'a', 'gentle', 'slope', 'at', 'the', 'top', 'he', 'found', 'a', 'small', 'clearing', 'in', 'the', 'center', 'there', 'was', 'a', 'pool', 'of', 'crystal', 'clear', 'water', 'its', 'surface', 'so', 'still', 'it', 'was', 'like', 'a', 'mirror']\n",
      "[]\n",
      "['leo', 'knelt', 'down', 'to', 'look', 'closer', 'to', 'his', 'amazement', 'he', 'saw', 'images', 'in', 'the', 'water', 'images', 'of', 'a', 'time', 'long', 'past', 'he', 'saw', 'ancient', 'tribes', 'dancing', 'around', 'a', 'fire', 'their', 'faces', 'painted', 'with', 'colors', 'their', 'laughter', 'echoing', 'in', 'the', 'night', 'he', 'saw', 'great', 'beasts', 'roaming', 'the', 'land', 'their', 'forms', 'both', 'terrifying', 'and', 'magnificent']\n",
      "[]\n",
      "['as', 'he', 'watched', 'the', 'images', 'shifted', 'now', 'he', 'saw', 'a', 'young', 'girl', 'her', 'eyes', 'as', 'bright', 'as', 'the', 'stars', 'running', 'through', 'the', 'very', 'same', 'forest', 'she', 'seemed', 'to', 'be', 'searching', 'for', 'something', 'her', 'expression', 'filled', 'with', 'determination', 'leo', 'felt', 'a', 'strange', 'connection', 'to', 'her', 'as', 'if', 'their', 'fates', 'were', 'intertwined']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T08:05:52.840773Z",
     "start_time": "2025-06-23T08:05:52.828805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        counter = self.count_corpus(tokens)\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        self.unk, uniq_tokens = 0, ['<unk>'] + reserved_tokens\n",
    "\n",
    "        uniq_tokens += [token for token, freq in self.token_freqs\n",
    "                        if freq >= min_freq and token not in uniq_tokens]\n",
    "        self.idx_to_token, self.token_to_idx = [], dict()\n",
    "        for token in uniq_tokens:\n",
    "            self.idx_to_token.append(token)\n",
    "            self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    def count_corpus(self, tokens):\n",
    "        \"\"\"统计标记的频率\"\"\"\n",
    "        if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        return collections.Counter(tokens)"
   ],
   "id": "fae1fb6334ca8076",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T08:06:35.643783Z",
     "start_time": "2025-06-23T08:06:35.632781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab = Vocab(tokens)\n",
    "print(list(vocab.token_to_idx.items())[:10])"
   ],
   "id": "271f302f484f31cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<unk>', 0), ('the', 1), ('a', 2), ('he', 3), ('to', 4), ('of', 5), ('and', 6), ('in', 7), ('was', 8), ('leo', 9)]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 将每一条文本行转换成一个数字索引表",
   "id": "d88990816bbb6f89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T08:10:33.830907Z",
     "start_time": "2025-06-23T08:10:33.817970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in [0, 10]:\n",
    "    print('words:', tokens[i])\n",
    "    print('indices:', vocab[tokens[i]])"
   ],
   "id": "17dacee25b7f4b6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['in', 'a', 'quiet', 'corner', 'of', 'the', 'world', 'there', 'lay', 'an', 'ancient', 'forest', 'its', 'edges', 'blurred', 'by', 'mist', 'and', 'time', 'few', 'dared', 'to', 'enter', 'for', 'tales', 'spoke', 'of', 'strange', 'lights', 'haunting', 'sounds', 'and', 'paths', 'that', 'twisted', 'back', 'on', 'themselves', 'but', 'for', 'leo', 'a', 'curious', 'fifteen', 'year', 'old', 'with', 'a', 'heart', 'full', 'of', 'wonder', 'it', 'was', 'an', 'irresistible', 'mystery']\n",
      "indices: [7, 2, 221, 122, 5, 1, 123, 81, 82, 83, 84, 19, 24, 222, 223, 63, 85, 6, 32, 124, 224, 4, 225, 33, 226, 86, 5, 87, 227, 228, 229, 6, 125, 13, 230, 48, 23, 231, 22, 33, 9, 2, 232, 233, 234, 235, 12, 2, 64, 126, 5, 236, 18, 8, 83, 237, 127]\n",
      "words: ['as', 'he', 'watched', 'the', 'images', 'shifted', 'now', 'he', 'saw', 'a', 'young', 'girl', 'her', 'eyes', 'as', 'bright', 'as', 'the', 'stars', 'running', 'through', 'the', 'very', 'same', 'forest', 'she', 'seemed', 'to', 'be', 'searching', 'for', 'something', 'her', 'expression', 'filled', 'with', 'determination', 'leo', 'felt', 'a', 'strange', 'connection', 'to', 'her', 'as', 'if', 'their', 'fates', 'were', 'intertwined']\n",
      "indices: [10, 3, 309, 1, 43, 310, 71, 3, 42, 2, 155, 156, 29, 39, 10, 311, 10, 1, 157, 158, 41, 1, 96, 312, 19, 20, 25, 4, 54, 313, 33, 159, 29, 314, 97, 12, 315, 9, 98, 2, 87, 160, 4, 29, 10, 26, 28, 316, 35, 161]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6b1ef6ff7dc92cb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
